{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXHMaamLnuQaujyALjv4R6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Balasiva21/Balasiva-/blob/main/Wikipedia%20\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"view-in-github\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"<a href=\\\"https://colab.research.google.com/github/Kalyanianikkath/NM-Genrative-AI/blob/main/wikipedia_bot.ipynb\\\" target=\\\"_parent\\\"><img src=\\\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\\\"Open In Colab\\\"/></a>\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 729\n",
        "        },\n",
        "        \"id\": \"Iazbf7sElSKF\",\n",
        "        \"outputId\": \"3d5032de-fd21-4041-bd50-3df87c7cd74d\"\n",
        "      },\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"name\": \"stdout\",\n",
        "          \"output_type\": \"stream\",\n",
        "          \"text\": [\n",
        "            \"  Preparing metadata (setup.py) ... \\u001b[?25l\\u001b[?25hdone\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m30.7/30.7 MB\\u001b[0m \\u001b[31m29.5 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m46.5/46.5 MB\\u001b[0m \\u001b[31m11.4 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m322.2/322.2 kB\\u001b[0m \\u001b[31m14.2 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m95.2/95.2 kB\\u001b[0m \\u001b[31m6.5 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m11.3/11.3 MB\\u001b[0m \\u001b[31m42.0 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m72.0/72.0 kB\\u001b[0m \\u001b[31m4.3 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m62.3/62.3 kB\\u001b[0m \\u001b[31m3.2 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[?25h  Building wheel for wikipedia (setup.py) ... \\u001b[?25l\\u001b[?25hdone\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"ename\": \"MessageError\",\n",
        "          \"evalue\": \"Error: credential propagation was unsuccessful\",\n",
        "          \"output_type\": \"error\",\n",
        "          \"traceback\": [\n",
        "            \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n",
        "            \"\\u001b[0;31mMessageError\\u001b[0m                              Traceback (most recent call last)\",\n",
        "            \"\\u001b[0;32m<ipython-input-1-6fd4f08e5a38>\\u001b[0m in \\u001b[0;36m<cell line: 0>\\u001b[0;34m()\\u001b[0m\\n\\u001b[1;32m      4\\u001b[0m \\u001b[0;31m# Authenticate and import\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m      5\\u001b[0m \\u001b[0;32mfrom\\u001b[0m \\u001b[0mgoogle\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mcolab\\u001b[0m \\u001b[0;32mimport\\u001b[0m \\u001b[0mauth\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m----> 6\\u001b[0;31m \\u001b[0mauth\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mauthenticate_user\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m      7\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m      8\\u001b[0m \\u001b[0;32mimport\\u001b[0m \\u001b[0mwikipedia\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
        "            \"\\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/auth.py\\u001b[0m in \\u001b[0;36mauthenticate_user\\u001b[0;34m(clear_output, project_id)\\u001b[0m\\n\\u001b[1;32m    258\\u001b[0m   \\u001b[0;32mif\\u001b[0m \\u001b[0;32mnot\\u001b[0m \\u001b[0m_check_adc\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0m_CredentialType\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mUSER\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    259\\u001b[0m     \\u001b[0;32mif\\u001b[0m \\u001b[0muse_auth_ephem\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 260\\u001b[0;31m       _message.blocking_request(\\n\\u001b[0m\\u001b[1;32m    261\\u001b[0m           \\u001b[0;34m'request_auth'\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    262\\u001b[0m           \\u001b[0mrequest\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0;34m{\\u001b[0m\\u001b[0;34m'authType'\\u001b[0m\\u001b[0;34m:\\u001b[0m \\u001b[0;34m'auth_user_ephemeral'\\u001b[0m\\u001b[0;34m}\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
        "            \"\\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\\u001b[0m in \\u001b[0;36mblocking_request\\u001b[0;34m(request_type, request, timeout_sec, parent)\\u001b[0m\\n\\u001b[1;32m    174\\u001b[0m       \\u001b[0mrequest_type\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mrequest\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mparent\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0mparent\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mexpect_reply\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0;32mTrue\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    175\\u001b[0m   )\\n\\u001b[0;32m--> 176\\u001b[0;31m   \\u001b[0;32mreturn\\u001b[0m \\u001b[0mread_reply_from_input\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mrequest_id\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mtimeout_sec\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\",\n",
        "            \"\\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\\u001b[0m in \\u001b[0;36mread_reply_from_input\\u001b[0;34m(message_id, timeout_sec)\\u001b[0m\\n\\u001b[1;32m    101\\u001b[0m     ):\\n\\u001b[1;32m    102\\u001b[0m       \\u001b[0;32mif\\u001b[0m \\u001b[0;34m'error'\\u001b[0m \\u001b[0;32min\\u001b[0m \\u001b[0mreply\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 103\\u001b[0;31m         \\u001b[0;32mraise\\u001b[0m \\u001b[0mMessageError\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mreply\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0;34m'error'\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    104\\u001b[0m       \\u001b[0;32mreturn\\u001b[0m \\u001b[0mreply\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mget\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m'data'\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;32mNone\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    105\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
        "            \"\\u001b[0;31mMessageError\\u001b[0m: Error: credential propagation was unsuccessful\"\n",
        "          ]\n",
        "        }\n",
        "      ],\n",
        "      \"source\": [\n",
        "        \"# Install dependencies\\n\",\n",
        "        \"!pip install google-cloud-aiplatform wikipedia langchain faiss-cpu gradio transformers --quiet\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Authenticate and import\\n\",\n",
        "        \"from google.colab import auth\\n\",\n",
        "        \"auth.authenticate_user()\\n\",\n",
        "        \"\\n\",\n",
        "        \"import wikipedia\\n\",\n",
        "        \"import gradio as gr\\n\",\n",
        "        \"from langchain.vectorstores import FAISS\\n\",\n",
        "        \"from langchain.embeddings import HuggingFaceEmbeddings\\n\",\n",
        "        \"from langchain.docstore.document import Document\\n\",\n",
        "        \"from langchain.chains import RetrievalQA\\n\",\n",
        "        \"from langchain.llms.base import LLM\\n\",\n",
        "        \"import vertexai\\n\",\n",
        "        \"from vertexai.language_models import ChatModel\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Initialize Vertex AI\\n\",\n",
        "        \"PROJECT_ID = \\\"your-gcp-project-id\\\"  # <<< REPLACE THIS WITH YOUR GCP PROJECT ID\\n\",\n",
        "        \"REGION = \\\"us-central1\\\"\\n\",\n",
        "        \"vertexai.init(project=PROJECT_ID, location=REGION)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Gemini wrapper for LangChain\\n\",\n",
        "        \"class GeminiLLM(LLM):\\n\",\n",
        "        \"    def __init__(self, model_name=\\\"gemini-1.0-pro\\\", temperature=0.7):\\n\",\n",
        "        \"        self.chat_model = ChatModel.from_pretrained(model_name)\\n\",\n",
        "        \"        self.chat = self.chat_model.start_chat()\\n\",\n",
        "        \"        self.temperature = temperature\\n\",\n",
        "        \"    def _call(self, prompt: str, stop=None):\\n\",\n",
        "        \"        response = self.chat.send_message(prompt)\\n\",\n",
        "        \"        return response.text\\n\",\n",
        "        \"    @property\\n\",\n",
        "        \"    def _llm_type(self):\\n\",\n",
        "        \"        return \\\"gemini\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Wikipedia and FAISS functions\\n\",\n",
        "        \"def get_wikipedia_content(query, sentences=10):\\n\",\n",
        "        \"    try:\\n\",\n",
        "        \"        summary = wikipedia.summary(query, sentences=sentences, auto_suggest=True, redirect=True)\\n\",\n",
        "        \"        return Document(page_content=summary, metadata={\\\"source\\\": \\\"Wikipedia\\\", \\\"topic\\\": query})\\n\",\n",
        "        \"    except wikipedia.exceptions.PageError:\\n\",\n",
        "        \"        return None\\n\",\n",
        "        \"\\n\",\n",
        "        \"def create_vectorstore(documents):\\n\",\n",
        "        \"    embeddings = HuggingFaceEmbeddings(model_name=\\\"sentence-transformers/all-MiniLM-L6-v2\\\")\\n\",\n",
        "        \"    return FAISS.from_documents(documents, embeddings)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Load Gemini and initialize global chatbot state\\n\",\n",
        "        \"llm = GeminiLLM()\\n\",\n",
        "        \"retriever = None\\n\",\n",
        "        \"qa_chain = None\\n\",\n",
        "        \"current_topic = \\\"\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Setup and answer functions\\n\",\n",
        "        \"def setup_chatbot(topic):\\n\",\n",
        "        \"    global retriever, qa_chain, current_topic\\n\",\n",
        "        \"    doc = get_wikipedia_content(topic)\\n\",\n",
        "        \"    if doc is None:\\n\",\n",
        "        \"        return \\\"Couldn't find that topic on Wikipedia.\\\"\\n\",\n",
        "        \"    vectorstore = create_vectorstore([doc])\\n\",\n",
        "        \"    retriever = vectorstore.as_retriever(search_kwargs={\\\"k\\\": 1})\\n\",\n",
        "        \"    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\\n\",\n",
        "        \"    current_topic = topic\\n\",\n",
        "        \"    return f\\\"Gemini is ready! Ask anything about **{topic}**.\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"def answer_question(user_question):\\n\",\n",
        "        \"    if qa_chain is None:\\n\",\n",
        "        \"        return \\\"Please set a topic first using the box above.\\\"\\n\",\n",
        "        \"    return qa_chain.run(user_question)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Gradio Interface\\n\",\n",
        "        \"with gr.Blocks() as demo:\\n\",\n",
        "        \"    gr.Markdown(\\\"# Wikipedia Chatbot (Gemini + LangChain + FAISS)\\\")\\n\",\n",
        "        \"    with gr.Row():\\n\",\n",
        "        \"        topic_input = gr.Textbox(label=\\\"Wikipedia Topic (e.g. Alan Turing)\\\")\\n\",\n",
        "        \"        setup_btn = gr.Button(\\\"Load Topic\\\")\\n\",\n",
        "        \"    chatbot_output = gr.Textbox(label=\\\"System Message\\\", interactive=False)\\n\",\n",
        "        \"    with gr.Row():\\n\",\n",
        "        \"        question_input = gr.Textbox(label=\\\"Your Question\\\")\\n\",\n",
        "        \"        answer_output = gr.Textbox(label=\\\"Answer\\\", interactive=False)\\n\",\n",
        "        \"    setup_btn.click(fn=setup_chatbot, inputs=topic_input, outputs=chatbot_output)\\n\",\n",
        "        \"    question_input.submit(fn=answer_question, inputs=question_input, outputs=answer_output)\\n\",\n",
        "        \"\\n\",\n",
        "        \"demo.launch()\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 1000\n",
        "        },\n",
        "        \"id\": \"WqSP9av9ov79\",\n",
        "        \"outputId\": \"3cf8edcd-5e0e-4098-86f8-267d0269b295\"\n",
        "      },\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"name\": \"stdout\",\n",
        "          \"output_type\": \"stream\",\n",
        "          \"text\": [\n",
        "            \"Collecting langchain_community\\n\",\n",
        "            \"  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\\n\",\n",
        "            \"Collecting langchain-core<1.0.0,>=0.3.51 (from langchain_community)\\n\",\n",
        "            \"  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\\n\",\n",
        "            \"Collecting langchain<1.0.0,>=0.3.23 (from langchain_community)\\n\",\n",
        "            \"  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\\n\",\n",
        "            \"Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\\n\",\n",
        "            \"Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\\n\",\n",
        "            \"Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\\n\",\n",
        "            \"Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\\n\",\n",
        "            \"Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\\n\",\n",
        "            \"Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\\n\",\n",
        "            \"  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\\n\",\n",
        "            \"Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\\n\",\n",
        "            \"  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\\n\",\n",
        "            \"Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.23)\\n\",\n",
        "            \"Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\\n\",\n",
        "            \"  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\\n\",\n",
        "            \"Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\\n\",\n",
        "            \"Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\\n\",\n",
        "            \"Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\\n\",\n",
        "            \"Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\\n\",\n",
        "            \"Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\\n\",\n",
        "            \"Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\\n\",\n",
        "            \"Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\\n\",\n",
        "            \"Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\\n\",\n",
        "            \"Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\\n\",\n",
        "            \"  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\\n\",\n",
        "            \"Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\\n\",\n",
        "            \"  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\\n\",\n",
        "            \"Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.23->langchain_community)\\n\",\n",
        "            \"  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\\n\",\n",
        "            \"Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.11.2)\\n\",\n",
        "            \"Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (1.33)\\n\",\n",
        "            \"Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (24.2)\\n\",\n",
        "            \"Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (4.13.1)\\n\",\n",
        "            \"Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\\n\",\n",
        "            \"Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\\n\",\n",
        "            \"Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\\n\",\n",
        "            \"Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\\n\",\n",
        "            \"Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\\n\",\n",
        "            \"  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\\n\",\n",
        "            \"Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\\n\",\n",
        "            \"Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\\n\",\n",
        "            \"Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\\n\",\n",
        "            \"Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\\n\",\n",
        "            \"Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\\n\",\n",
        "            \"Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\\n\",\n",
        "            \"Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\\n\",\n",
        "            \"Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\\n\",\n",
        "            \"Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community) (3.0.0)\\n\",\n",
        "            \"Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\\n\",\n",
        "            \"Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.33.1)\\n\",\n",
        "            \"Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.4.0)\\n\",\n",
        "            \"Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\\n\",\n",
        "            \"  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\\n\",\n",
        "            \"Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\\n\",\n",
        "            \"Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m2.5/2.5 MB\\u001b[0m \\u001b[31m28.9 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\\n\",\n",
        "            \"Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\\n\",\n",
        "            \"Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "ip2Ml_pQcI1I",
        "outputId": "ebb078a5-a6c9-4878-b5bb-5a04ffa90ada"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-6-738e35dfd5b0>, line 219)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-738e35dfd5b0>\"\u001b[0;36m, line \u001b[0;32m219\u001b[0m\n\u001b[0;31m    \"Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\\\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    }
  ]
}